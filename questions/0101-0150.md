[![readme](https://img.shields.io/badge/README-blue)](/)
[![part01](https://img.shields.io/badge/0001--0050-blue)](0001-0050.md)
[![part02](https://img.shields.io/badge/0051--0100-blue)](0051-0100.md)
[![part04](https://img.shields.io/badge/0151--0200-blue)](0151-0200.md)
[![part05](https://img.shields.io/badge/0201--0250-blue)](0201-0250.md)
[![part06](https://img.shields.io/badge/0251--0300-blue)](0251-0300.md)
[![part07](https://img.shields.io/badge/0301--0350-blue)](0301-0350.md)
[![part08](https://img.shields.io/badge/0351--0400-blue)](0351-0400.md)
[![part09](https://img.shields.io/badge/0401--0450-blue)](0401-0450.md)
[![part10](https://img.shields.io/badge/0451--0500-blue)](0451-0500.md)
[![part11](https://img.shields.io/badge/0501--0550-blue)](0501-0550.md)
[![part12](https://img.shields.io/badge/0551--0600-blue)](0551-0600.md)
[![part13](https://img.shields.io/badge/0601--0650-blue)](0601-0650.md)
[![part14](https://img.shields.io/badge/0651--0700-blue)](0651-0700.md)
[![part15](https://img.shields.io/badge/0701--0750-blue)](0701-0750.md)
[![part16](https://img.shields.io/badge/0751--0800-blue)](0751-0800.md)
[![part17](https://img.shields.io/badge/0801--0850-blue)](0801-0850.md)
[![part18](https://img.shields.io/badge/0851--0900-blue)](0851-0900.md)
[![part19](https://img.shields.io/badge/0901--0926-blue)](0901-0926.md)



### Question 102: An application is real-time processing millions of events that are received through an API. What service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-102)

- [ ] Amazon SNS with fanout to an SQS queue for each application.
- [ ] Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application.
- [ ] Amazon Kinesis Firehose.
- [x] Amazon Kinesis Streams.



### Question 103: An application will ingest data at very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-103)

- [x] Amazon Kinesis Firehose.
- [ ] Amazon S3 Acceleration Transfer.
- [ ] Amazon SQS.
- [ ] Amazon SNS.



### Question 104: A Developer is creating a Lambda function and will be using external libraries that are not included in the standard Lambda libraries. What action would minimize the Lambda compute time consumed? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-104)

- [ ] Install the dependencies and external libraries at the beginning of the Lambda function.
- [x] Create a Lambda deployment package that includes the external libraries.
- [ ] Copy the external libraries to Amazon S3, and reference the external libraries to the S3 location.
- [ ] Install the external libraries in Lambda to be available to all Lambda functions.



### Question 105: During non-peak hours, a Developer wants to minimize the execution time of a full Amazon DynamoDB table scan without affecting normal workloads. The workloads average half of the strongly consistent read capacity units during non-peak hours. How would the Developer optimize this scan? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-105)

- [x] Use parallel scans while limiting the rate.
- [ ] Use sequential scans.
- [ ] Increase read capacity units during the scan operation.
- [ ] Change consistency to eventually consistent during the scan operation.



### Question 106: A large e-commerce site is being designed to deliver static objects from Amazon S3. The Amazon S3 bucket will serve more than 300 GET requests per second. What should be done to optimize performance? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-106)

- [x] Integrate Amazon CloudFront with Amazon S3.
- [ ] Enable Amazon S3 cross-region replication.
- [ ] Delete expired Amazon S3 server log files.
- [ ] Configure Amazon S3 lifecycle rules.
- [ ] Randomize Amazon S3 key name prefixes.



### Question 107: A Developer has an application that can upload tens of thousands of objects per second to Amazon S3 in parallel within a single AWS account. As part of new requirements, data stored in S3 must use server-side encryption with AWS KMS (SSE-KMS). After creating this change, the performance of the application is slower. Which of the following is MOST likely the cause of the application latency? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-107)

- [ ] Amazon S3 throttles the rate at which uploaded objects can be encrypted using Customer Master Keys.
- [x] The AWS KMS API calls limit is less than needed to achieve the desired performance.
- [ ] The client encryption of the objects is using a poor algorithm.
- [ ] KMS requires that an alias be used to create an independent display name that can be mapped to a CM.



### Question 108: A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain the application access log. What deployment policy would satisfy these requirements? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-108)

- [x] Rolling.
- [ ] All at once.
- [ ] Rolling with an additional batch.
- [ ] Immutable.



### Question 109: An application is designed to use Amazon SQS to manage messages from many independent senders. Each sender's messages must be processed in the order they are received. Which SQS feature should be implemented by the Developer? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-109)

- [x] Configure each sender with a unique MessageGroupId.
- [ ] Enable MessageDeduplicationIds on the SQS queue.
- [ ] Configure each message with unique MessageGroupIds.
- [ ] Enable ContentBasedDeduplication on the SQS queue.



### Question 110: A Lambda function is packaged for deployment to multiple environments, including development, test, production, etc. Each environment has a unique set of resources such as databases, etc. How can the Lambda function use the resources for the current environment? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-110)

- [ ] Apply tags to the Lambda functions.
- [ ] Hardcore resources in the source code.
- [x] Use environment variables for the Lambda functions.
- [ ] Use a separate function for development and production.



### Question 111: A Developer needs temporary access to resources in a second account. What is the MOST secure way to achieve this? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-111)

- [ ] Use the Amazon Cognito user pools to get short-lived credentials for the second account.
- [ ] Create a dedicated IAM access key for the second account, and send it by mail.
- [x] Create a cross-account access role, and use sts:AssumeRole API to get short-lived credentials.
- [ ] Establish trust, and add an SSH key for the second account to the IAM user.



### Question 112: A Developer needs to use AWS X-Ray to monitor an application that is deployed on EC2 instances. What steps have to be executed to perform the monitoring? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-112)

- [ ] Deploy the X-Ray SDK with the application and use X-Ray annotation.
- [x] Install the X-Ray daemon and instrument the application code.
- [ ] Install the X-Ray daemon and configure it to forward data to Amazon CloudWatch Events.
- [ ] Deploy the X-Ray SDK with the application and instrument the application code.



### Question 113: A static website is hosted in an Amazon S3 bucket. Several HTML pages on the site use JavaScript to download images from another Amazon S3 bucket. These images are not displayed when users browse the site. What is the possible cause for the issue? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-113)

- [ ] The referenced Amazon S3 bucket is in another region.
- [ ] The images must be stored in the same Amazon S3 bucket.
- [ ] Port 80 must be opened on the security group in which the Amazon S3 bucket is located.
- [x] Cross-Origin Resource Sharing must be enabled on the Amazon S3 bucket.



### Question 115: A development team consists of 10 team members. Similar to a home directory for each team member, the manager wants to grant access to user-specific folders in an Amazon S3 bucket. For the team member with the username "TeamMemberX", the snippet of the IAM policy looks like this: `{ "Sid": "AllowS3ActionToFolders", "Effect": "Allow", "Action": ["s3:*"], "Resource": ["arn:aws:s3:::company-name/home/TeamMemberX/*"] }`. Instead of creating distinct policies for each team member, what approach can be used to make this policy snippet generic for all team members? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-115)

- [ ] Use IAM policy condition.
- [ ] Use IAM policy principle.
- [x] Use IAM policy variables.
- [ ] Use IAM policy resource.



### Question 116: A company needs to encrypt data at rest, but it wants to leverage an AWS-managed service using its own master key. Which of the following AWS services can be used to meet these requirements? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-116)

- [ ] SSE with Amazon S3.
- [x] SSE with AWS KMS.
- [ ] Client-side encryption.
- [ ] AWS IAM roles and policies.



### Question 117: A company wants to implement continuous integration for its workloads on AWS. The company wants to trigger unit tests in its pipeline for commits to its code repository and wants to be notified of failure events in the pipeline. How can these requirements be met? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-117)

- [x] Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon SNS to trigger notifications of failure events.
- [ ] Store the source code in GitHub. Create a CodePipeline to automate unit testing. Use Amazon SES to trigger notifications of failure events.
- [ ] Store the source code on GitHub. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events.
- [ ] Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events.



### Question 118: An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default VisibilityTimeout value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-118)

- [x] Use the ChangeMessageVisibility API to increase the VisibilityTimeout, then use the DeleteMessage API to delete the message.
- [ ] Use the DeleteMessage API call to delete the message from the queue, then call DeleteQueue API to remove the queue.
- [ ] Use the ChangeMessageVisibility API to decrease the timeout value, then use the DeleteMessage API to delete the message.
- [ ] Use the DeleteMessageVisibility API to cancel the VisibilityTimeout, then use the DeleteMessage API to delete the message.



### Question 119: A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-119)

- [ ] Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.
- [x] Amazon Cognito with MFA.
- [ ] AWS Directory Service.
- [ ] AWS IAM with MFA enabled.



### Question 120: A set of APIs is exposed to customers using the Amazon API Gateway. These APIs have caching enabled on the API Gateway. Customers have asked for an option to invalidate this cache for each of the APIs. What action can be taken to allow API customers to invalidate the API Cache? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-120)

- [ ] Ask customers to use AWS credentials to call the InvalidateCache API.
- [ ] Ask customers to invoke an AWS API endpoint that invalidates the cache.
- [x] Ask customers to pass an HTTP header called Cache-Control:max-age=0.
- [ ] Ask customers to add a query string parameter called "INVALIDATE_CACHE" when making an API call.



### Question 121: A Developer has created a software package to be deployed on multiple EC2 instances using IAM roles. What actions could be performed to verify IAM access to get records from Amazon Kinesis Streams? (Select TWO.) [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-121)

- [ ] Use the AWS CLI to retrieve the IAM group.
- [ ] Query Amazon EC2 metadata for in-line IAM policies.
- [ ] Request a token from AWS STS, and perform a describe action.
- [x] Perform a get action using the --dry-run argument.
- [x] Validate the IAM role policy with the IAM policy simulator.



### Question 122: A company is using AWS CodeBuild to compile a website from source code stored in AWS CodeCommit. A recent change to the source code has resulted in the CodeBuild project being unable to successfully compile the website. How should the Developer identify the cause of the failures? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-122)

- [ ] Modify the buildspec.yml file to include steps to send the output of build commands to Amazon CloudWatch.
- [ ] Use a custom Docker image that includes the AWS X-Ray agent in the AWS CodeBuild project configuration.
- [x] Check the build logs of the failed phase in the last build attempt in the AWS CodeBuild project build history.
- [ ] Manually re-run the build process on a local machine so that the output can be visualized.



### Question 123: For a deployment using AWS CodeDeploy, what is the run order of the hooks for in-place deployments? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-123)

- [ ] BeforeInstall -> ApplicationStop -> ApplicationStart -> AfterInstall.
- [x] ApplicationStop -> BeforeInstall -> AfterInstall -> ApplicationStart.
- [ ] BeforeInstall -> ApplicationStop -> ValidateService -> ApplicationStart.
- [ ] ApplicationStop -> BeforeInstall -> ValidateService -> ApplicationStart.



### Question 124: Where should an Elastic Beanstalk configuration file named healthcheckur1.config be placed in the application source bundle? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-124)

- [ ] In the root of the application.
- [ ] In the bin folder.
- [ ] In healthcheckur1.config.ebextension under root.
- [x] In the .ebextensions folder.



### Question 125: The Developer for a retail company must integrate a fraud detection solution into the order processing solution. The fraud detection solution takes between ten and thirty minutes to verify an order. At peak, the website can receive one hundred orders per minute. What is the most scalable method to add the fraud detection solution to the order processing pipeline? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-125)

- [ ] Add all new orders to an Amazon SQS queue. Configure a fleet of 10 EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fail status.
- [x] Add all new orders to an Amazon SQS queue. Configure an Auto Scaling group that uses the queue depth metric as its unit of scale to launch a dynamically-sized fleet of EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fail status.
- [ ] Add all new orders to an Amazon Kinesis Stream. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.
- [ ] Write all new orders to Amazon DynamoDB. Configure DynamoDB Streams to include all new orders. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.



### Question 126: A Developer uses AWS CodeDeploy to automate application deployment that connects to an external MySQL database. The Developer wants to securely access the encrypted secrets, such as API keys and database passwords. Which of the following solutions would involve the LEAST administrative effort? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-126)

- [ ] Save the secrets in Amazon S3 with AWS KMS server-side encryption, and use a signed URL to access them by using the IAM role from Amazon EC2 instances.
- [ ] Use the instance metadata to store the secrets and to programmatically access the secrets from EC2 instances.
- [ ] Use the Amazon DynamoDB client-side encryption library to save the secrets in DynamoDB and to programmatically access the secrets from EC2 instances.
- [x] Use AWS SSM Parameter Store to store the secrets and to programmatically access them by using the IAM role from EC2 instances.



### Question 127: An application stops working with the following error: `The specified bucket does not exist`. Where is the BEST place to start the root cause analysis? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-127)

- [ ] Check the Elastic Load Balancer logs for DeleteBucket requests.
- [ ] Check the application logs in Amazon CloudWatch Logs for Amazon S3 DeleteBucket errors.
- [ ] Check AWS X-Ray for Amazon S3 DeleteBucket alarms.
- [x] Check AWS CloudTrail for a DeleteBucket event.



### Question 128: A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-128)

- [ ] Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.
- [x] Run the `aws configure` CLI command, and provide the Developer's IAM access key ID and secret access key.
- [ ] Specify the Developer's IAM user name and password as parameters for each CLI command.
- [ ] Use the Developer's IAM role when making the CLI command.



### Question 129: An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-129)

- [x] Lambda will scale out to execute the requests concurrently.
- [ ] Lambda will handle the requests sequentially in the order received.
- [ ] Lambda will process multiple images in a single execution.
- [ ] Lambda will add more compute to each execution to reduce processing time.



### Question 130: A company is building a stock trading application that requires sub-millisecond latency in processing trading requests. Amazon DynamoDB is used to store all the trading data that is used to process each request. After load testing the application, the development team found that due to data retrieval times, the latency requirement was not satisfied. Because of sudden high spikes in the number of requests, DynamoDB read capacity has to be significantly over-provisioned to avoid throttling. What steps should be taken to meet latency requirements and reduce the cost of running the application? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-130)

- [ ] Add Global Secondary Indexes for trading data.
- [ ] Store trading data in Amazon S3 and use Transfer Acceleration.
- [ ] Add retries with exponential back-off for DynamoDB queries.
- [x] Use DynamoDB Accelerator to cache trading data.



### Question 131: A Developer created a Lambda function for a web application backend. When testing the Lambda function from the AWS Lambda console, the Developer can see that the function is being executed, but there is no log data being generated in Amazon CloudWatch Logs, even after several minutes. What could cause this situation? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-131)

- [ ] The Lambda function does not have any explicit log statements for the log data to send to CloudWatch Logs.
- [ ] The Lambda function is missing CloudWatch Logs as a source trigger to send log data.
- [x] The execution role for the Lambda function is missing permissions to write log data to the CloudWatch Logs.
- [ ] The Lambda function is missing a target CloudWatch Log group.



### Question 132: Amazon S3 has the following structure: s3://BUCKET/FOLDERNAME/FILENAME.zip. Which S3 best practice would optimize performance with thousands of PUT requests each second to a single bucket? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-132)

- [ ] Prefix folder names with user ID; for example, s3://BUCKET/2013-FOLDERNAME/FILENAME.zip.
- [ ] Prefix file names with timestamps; for example, s3://BUCKET/FOLDERNAME/2013-26-05-15-00-00-FILENAME.zip.
- [ ] Prefix file names with random hex hashes; for example, s3://BUCKET/FOLDERNAME/23a6-FILENAME.zip.
- [x] Prefix folder names with random hex hashes; for example, s3://BUCKET/23a6-FOLDERNAME/FILENAME.zip.



### Question 133: An application has hundreds of users. Each user may use multiple devices to access the application. The Developer wants to assign unique identifiers to these users regardless of the device they use. Which of the following methods should be used to obtain unique identifiers? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-133)

- [ ] Create a user table in Amazon DynamoDB as key-value pairs of users and their devices. Use these keys as unique identifiers.
- [ ] Use IAM-generated access key IDs for the users as the unique identifier, but do not store secret keys.
- [x] Implement developer-authenticated identities by using Amazon Cognito, and get credentials for these identities.
- [ ] Assign IAM users and roles to the users. Use the unique IAM resource ID as the unique identifier.



### Question 134: What are the steps to using the AWS CLI to launch a templatized serverless application? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-134)

- [ ] Use AWS CloudFormation get-template then CloudFormation execute-change-set.
- [ ] Use AWS CloudFormation validate-template then CloudFormation create-change-set.
- [x] Use the AWS CloudFormation package then CloudFormation deploy.
- [ ] Use AWS CloudFormation create-stack then CloudFormation update-stack.



### Question 135: A deployment package uses the AWS CLI to copy files into any S3 bucket in the account, using access keys stored in environment variables. The package is running on EC2 instances, and the instances have been modified to run with an assumed IAM role and a more restrictive policy that allows access to only one bucket. After the change, the Developer logs into the host and still has the ability to write into all of the S3 buckets in that account. What is the MOST likely cause of this situation? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-135)

- [ ] An IAM inline policy is being used in the IAM role.
- [ ] An IAM-managed policy is being used in the IAM role.
- [ ] The AWS CLI is corrupt and needs to be reinstalled.
- [x] The AWS credential provider looks for instance profile credentials last.



### Question 136: When a Developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters. What is the recommended solution? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-136)

- [ ] Add the export LC_ALL="en_US.utf8" command to the pre_build section to ensure POSIX localization.
- [ ] Use Amazon Cognito to store key-value pairs for large numbers of environment variables.
- [ ] Update the settings for the building project to use an Amazon S3 bucket for large numbers of environment variables.
- [x] Use AWS Systems Manager Parameter Store to store large numbers of environment variables.



### Question 137: A Developer has been asked to build a real-time dashboard web application to visualize the key prefixes and storage size of objects in Amazon S3 buckets. Amazon DynamoDB will be used to store the Amazon S3 metadata. What is the optimal and MOST cost-effective design to ensure that the real-time dashboard is kept up to date with the state of the objects in the Amazon S3 buckets? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-137)

- [ ] Use an Amazon CloudWatch event backed by an AWS Lambda function. Issue an Amazon S3 API call to get a list of all Amazon S3 objects and persist the metadata within DynamoDB. Have the web application poll the DynamoDB table to reflect this change.
- [x] Use Amazon S3 Event Notification backed by a Lambda function to persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.
- [ ] Run a cron job within an Amazon EC2 instance to list all objects within Amazon S3 and persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.
- [ ] Create a new Amazon EMR cluster to get all the metadata about Amazon S3 objects; persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.



### Question 138: An application overwrites an object in Amazon S3, and then immediately reads the same object. Why would the application sometimes retrieve the old version of the object? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-138)

- [x] S3 overwrite PUTS are eventually consistent, so the application may read the old object.
- [ ] The application needs to add extra metadata to label the latest version when uploading to Amazon S3.
- [ ] All S3 PUTS are eventually consistent, so the application may read the old object.
- [ ] The application needs to explicitly specify the latest version when retrieving the object.



### Question 139: An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file. How should the Developer code the application? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-139)

- [ ] Use the KMS Encrypt API to encrypt the data. Store the encrypted data key and data.
- [ ] Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data.
- [x] Use the KMS GenerateDataKey API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data.
- [ ] Upload the data to an S3 bucket using server-side encryption with an AWS KMS key.



### Question 140: A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-140)

- [ ] Configure AWS CloudTrail logging to investigate the invocation failures.
- [x] Configure Dead Letter Queues by sending events to Amazon SQS for investigation.
- [ ] Configure Amazon Simple Workflow Service to process any direct unprocessed events.
- [ ] Configure AWS Config to process any direct unprocessed events.



### Question 141: A developer is setting up Amazon API Gateway for their company's products. The API will be used by registered developers to query and update their environments. The company wants to limit the amount of requests end users can send for both cost and security reasons. Management wants to offer registered developers the option of buying larger packages that allow for more requests. How can the developer accomplish this with the LEAST amount of overhead management? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-141)

- [ ] Enable throttling for the API Gateway stage. Set a value for both the rate and burst capacity. If a registered user chooses a larger package, create a stage for them, adjust the values, and share the new URL with them.
- [ ] Set up Amazon CloudWatch API logging in API Gateway. Create a filter based on the user and requestTime fields and create an alarm on this filter. Write an AWS Lambda function to analyze the values and requester information, and respond accordingly. Set up the function as the target for the alarm. If a registered user chooses a larger package, update the Lambda code with the values.
- [ ] Enable Amazon CloudWatch metrics for the API Gateway stage. Set up CloudWatch alarms based on the Count metric and the ApiName, Method, Resource, and Stage dimensions to alert when request rates pass the threshold. Set the alarm action to Deny. If a registered user chooses a larger package, create a user-specific alarm and adjust the values.
- [x] Set up a default usage plan, specify values for the rate and burst capacity, and associate it with a stage. If a registered user chooses a larger package, create a custom plan with the appropriate values and associate the plan with the user.



### Question 142: A developer is refactoring a monolithic application. The application takes a POST request and performs several operations. Some of the operations are in parallel while others run sequentially. These operations have been refactored into individual AWS Lambda functions. The POST request will be processed by Amazon API Gateway. How should the developer invoke the Lambda functions in the same sequence using API Gateway? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-142)

- [ ] Use Amazon SQS to invoke the Lambda functions.
- [ ] Use an AWS Step Functions activity to run the Lambda functions.
- [ ] Use Amazon SNS to trigger the Lambda functions.
- [x] Use an AWS Step Functions state machine to orchestrate the Lambda functions.



### Question 143: A company is adding stored value (or gift card) capability to its highly popular casual gaming website. Users need to be able to trade this value for other users' items on the platform. This would require both users' records to be updated as a single transaction, or both users' records to be completely rolled back. Which AWS database options can provide the transactional capability required for this new feature? (Select TWO.) [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-143)

- [ ] Amazon DynamoDB with operations made with the ConsistentRead parameter set to true.
- [ ] Amazon ElastiCache for Memcached with operations made within a transaction block.
- [x] Amazon Aurora MySQL with operations made within a transaction block.
- [x] Amazon DynamoDB with reads and writes made by using Transact* operations.
- [ ] Amazon Redshift with operations made within a transaction block.



### Question 144: A developer is creating an AWS Lambda function that generates a new file each time it runs. Each new file must be checked into an AWS CodeCommit repository hosted in the same AWS account. How should the developer accomplish this? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-144)

- [ ] When the Lambda function starts, use the Git CLI to clone the repository. Check the new file into the cloned repository and push the change.
- [ ] After the new file is created in Lambda, use cURL to invoke the CodeCommit API. Send the file to the repository.
- [x] Use an AWS SDK to instantiate a CodeCommit client. Invoke the PutFile method to add the file to the repository.
- [ ] Upload the new file to an Amazon S3 bucket. Create an AWS Step Function to accept S3 events. In the Step Function, add the new file to the repository.



### Question 145: A developer must ensure that the IAM credentials used by an application in Amazon EC2 are not misused or compromised. What should the developer use to keep user credentials secure? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-145)

- [ ] Environment variables.
- [ ] AWS credentials file.
- [x] Instance profile credentials.
- [ ] Command line options.



### Question 146: A company has an application where reading objects from Amazon S3 is based on the type of user. The user types are registered user and guest user. The company has 25,000 users and is growing. Information is pulled from an S3 bucket depending on the user type. Which approaches are recommended to provide access to both user types? (Select TWO.) [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-146)

- [ ] Provide a different access key and secret access key in the application code for registered users and guest users to provide read access to the objects.
- [ ] Use S3 bucket policies to restrict read access to specific IAM users.
- [x] Use Amazon Cognito to provide access using authenticated and unauthenticated roles.
- [ ] Create a new IAM user for each user and grant read access.
- [x] Use the AWS IAM service and let the application assume the different roles using the AWS Security Token Service (AWS STS) AssumeRole action depending on the type of user and provide read access to Amazon S3 using the assumed role.



### Question 147: A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-147)

- [ ] Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.
- [ ] Use Amazon Cognito user pools, federate with the SAML provider and use user pool groups with an IAM policy.
- [x] Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the cognitoidentity.amazonaws.com:sub variable to grant access to the employees.
- [ ] Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.



### Question 148: A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-148)

- [ ] Compress the application to a .zip file and upload it into AWS Lambda.
- [ ] Test the new AWS Lambda function by first tracing it in AWS X-Ray.
- [x] Bundle the serverless application using a SAM package.
- [ ] Create the application environment using the eb create my-env command.



### Question 149: An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-149)

- [ ] Use server-side encryption with Amazon S3-managed keys.
- [ ] Use server-side encryption with AWS KMS-managed keys.
- [ ] Use client-side encryption with customer master keys.
- [x] Use server-side encryption with customer-provided keys.



### Question 150: A development team is working on a mobile app that allows users to upload pictures to Amazon S3. The team expects the app will be used by hundreds of thousands of users during a single event simultaneously. Once the pictures are uploaded, the backend service will scan and parse the pictures for inappropriate content. Which approach is the MOST resilient way to achieve this goal, which also smooths out temporary volume spikes for the backend service? [![exp](https://img.shields.io/badge/Explanation-green)](/explanations/0101-0150.md#question-150)

- [ ] Develop an AWS Lambda function to check the upload folder in the S3 bucket. If newly uploaded pictures are detected, the Lambda function will scan and parse them.
- [x] Once a picture is uploaded to Amazon S3, publish the event to an Amazon SQS queue. Use the queue as an event source to trigger an AWS Lambda function. In the Lambda function, scan and parse the picture.
- [ ] When the user uploads a picture, invoke an API hosted in Amazon API Gateway. The API will invoke an AWS Lambda function to scan and parse the picture.
- [ ] Create a state machine in AWS Step Functions to check the upload folder in the S3 bucket. If a new picture is detected, invoke an AWS Lambda function to scan and parse it.
